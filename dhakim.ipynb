{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Preparations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Mounting"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Check, with local module, whether runtime is colaboratory\n",
    "\n",
    "try:  # local runtime\n",
    "    import library_check\n",
    "except ImportError:  # colab runtime\n",
    "    library_check = None\n",
    "    from google.colab import drive  # NOQA\n",
    "    drive.mount('/content/drive')  # NOQA\n",
    "    colaboratory = True\n",
    "else:\n",
    "    colaboratory = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Runtime Check"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS version: \t\tmacOS-11.5.2-arm64-arm-64bit\n",
      "Python version:\t\t3.8.10 | packaged by conda-forge | (default, May 11 2021, 06:27:18) \n",
      "[Clang 11.1.0 ]\n"
     ]
    }
   ],
   "source": [
    "# System Information\n",
    "\n",
    "import sys\n",
    "import platform\n",
    "print(f\"OS version: \\t\\t{platform.platform()}\\n\"\n",
    "      f\"Python version:\\t\\t{sys.version}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Library Installation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required libraries are installed.\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "\n",
    "if colaboratory:  # colab runtime\n",
    "    !pip install pydicom\n",
    "    # !pip install mxnet-cu101==1.7.0 d2l==0.16.6\n",
    "    !git clone https://github.com/kdha0727/lung-opacity-and-covid-chest-x-ray-detection/\n",
    "    %cd lung-opacity-and-covid-chest-x-ray-detection\n",
    "    import library_check\n",
    "    library_check.check()\n",
    "    import data_prep_utils\n",
    "    root = \"/content/drive/Shareddrives/2021 하계 SAT/\"\n",
    "    data_prep_utils.set_root(root)\n",
    "else:  # local runtime\n",
    "    library_check.check()\n",
    "    import data_prep_utils\n",
    "data_prep_utils.init()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# After all installation, import all libraries used.\n",
    "\n",
    "import inspect\n",
    "import random\n",
    "import pydicom as dcm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import seaborn as sns\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch\n",
    "import torchvision\n",
    "import torchsummary\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "\n",
    "from timm.models.efficientnet import tf_efficientnet_b4\n",
    "from effdet import get_efficientdet_config, DetBenchTrain\n",
    "from effdet.efficientdet import HeadNet, BiFpn, _init_weight\n",
    "\n",
    "from skimage import io, transform"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# And, import custom-defined Lazy Data Wrappers and Utilities\n",
    "\n",
    "from data_prep_utils import covid_19_radiography_dataset\n",
    "from data_prep_utils import rsna_pneumonia_detection_challenge\n",
    "\n",
    "from data_prep_utils.dataset import pil_loader, dicom_loader\n",
    "import train_utils"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Analysis and Processing\n",
    "\n",
    "* Note: All preprocessing processes are modularized as \"Data Wrapper\" package"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Class Information**\n",
    "* Normal: 0\n",
    "* Lung Opacity: 1\n",
    "* COVID-19: 2\n",
    "* Viral Pneumonia: 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: [\n",
      "\t('Normal', 0)\n",
      "\t('Lung_Opacity', 1)\n",
      "\t('COVID', 2)\n",
      "\t('Viral Pneumonia', 3) \n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print('\\n\\t'.join(map(str, ['Labels: [', *covid_19_radiography_dataset.class_to_idx.items()])), '\\n]')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Modeling via PyTorch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.pyplot._IonContext at 0x14f7c3370>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.ion()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class ImageWithPandas(VisionDataset):\n",
      "    \"\"\"A generic data loader where the image path and label is given as pandas DataFrame.\n",
      "\n",
      "    Args:\n",
      "        dataframe (pandas.DataFrame): A data table that contains image path, target class,\n",
      "            and extra outputs.\n",
      "        label_id (string): Data frame`s image path label string.\n",
      "        label_target (string): Data frame`s target class label string.\n",
      "        label_extras (tuple[string] or string, optional): Data frame`s label that will\n",
      "            be used for extra outputs.\n",
      "        root (string, optional): Root directory path. Use unless data frame`s column\n",
      "            contains file folders.\n",
      "        extension (string, optional): An extension that will be concatenated after\n",
      "            image file name. Use unless data frame`s column contains extension.\n",
      "        class_to_idx (dict[str, int], optional): A mapping table that converts class\n",
      "            label string into integer value. If not given, sorted index value will\n",
      "            be used as class integer value.\n",
      "        transform (callable, optional): A function/transform that takes in an image\n",
      "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "        target_transform (callable, optional): A function/transform that takes in the\n",
      "            target and transforms it.\n",
      "        extras_transform (callable, optional): A function/transform that takes in the\n",
      "            extra outputs and transforms it.\n",
      "        loader (callable, optional): A function to load an image given its path.\n",
      "\n",
      "     Attributes:\n",
      "        classes (list): List of the class names sorted alphabetically.\n",
      "        class_to_idx (dict): Dict with items (class_name, class_index).\n",
      "        samples (list): List of (sample path, class_index) tuples\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(\n",
      "            self,\n",
      "            dataframe: pd.DataFrame,\n",
      "            label_id: str,\n",
      "            label_target: str,\n",
      "            root: typing.Optional[typing.Union[str, os.PathLike]] = None,\n",
      "            extension: typing.Optional[str] = None,\n",
      "            class_to_idx: typing.Optional[typing.Dict[typing.Any, int]] = None,\n",
      "            transform: typing.Optional[typing.Callable] = None,\n",
      "            target_transform: typing.Optional[typing.Callable] = None,\n",
      "            extras_transform: typing.Optional[typing.Callable] = None,\n",
      "            loader: typing.Callable[[str], typing.Any] = default_loader,\n",
      "    ) -> None:\n",
      "\n",
      "        super(ImageWithPandas, self).__init__(root, None, transform, target_transform)\n",
      "\n",
      "        self.extras_transform = extras_transform\n",
      "        self.loader = loader\n",
      "        self.label_id = label_id\n",
      "        self.label_target = label_target\n",
      "\n",
      "        labels = [label_id, label_target]\n",
      "\n",
      "        samples = dataframe[labels].copy(deep=True)\n",
      "\n",
      "        assert extension.startswith('.') or extension is None\n",
      "        if root is not None:\n",
      "            root = os.path.expanduser(root)\n",
      "        if root is not None or extension is not None:\n",
      "            samples[label_id] = samples[label_id].map(\n",
      "                (lambda x: os.path.join(root, x + extension or ''))\n",
      "                if root is not None else (lambda x: x + extension)\n",
      "            )\n",
      "\n",
      "        classes = sorted(samples[label_target].unique())\n",
      "        if class_to_idx is None:\n",
      "            class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
      "        samples[label_target] = samples[label_target].map(lambda x: class_to_idx[x])\n",
      "\n",
      "        samples = samples.drop_duplicates()\n",
      "\n",
      "        self.ids = tuple(samples[label_id].drop_duplicates())\n",
      "        self.samples = samples\n",
      "        self.classes = classes\n",
      "        self.class_to_idx = class_to_idx\n",
      "        self.num_classes = len(class_to_idx)\n",
      "\n",
      "    def __len__(self):\n",
      "        return len(self.ids)\n",
      "\n",
      "    def __getitem__(self, index: int) -> ...:\n",
      "        image_id = self.ids[index]\n",
      "        row = self.samples[self.samples[self.label_id] == image_id]\n",
      "        path, target = row[self.label_id], row[self.label_target]\n",
      "        sample = self.loader(path.item())\n",
      "        if self.transform is not None:\n",
      "            sample = self.transform(sample)\n",
      "        if self.target_transform is not None:\n",
      "            target = self.target_transform(target)\n",
      "        else:\n",
      "            target = np.array(target)\n",
      "        return sample, target\n",
      "\n",
      "class ImageFolder(_ImageFolder):\n",
      "    \"\"\"A generic data loader where the images are arranged in root folder.\n",
      "\n",
      "    Args:\n",
      "        root (string): Root directory path.\n",
      "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "        target_transform (callable, optional): A function/transform that takes in the\n",
      "            target and transforms it.\n",
      "        loader (callable, optional): A function to load an image given its path.\n",
      "        is_valid_file (callable, optional): A function that takes path of an Image file\n",
      "            and check if the file is a valid file (used to check of corrupt files)\n",
      "\n",
      "     Attributes:\n",
      "        classes (list): List of the class names sorted alphabetically.\n",
      "        class_to_idx (dict): Dict with items (class_name, class_index).\n",
      "        imgs (list): List of (image path, class_index) tuples\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(\n",
      "            self,\n",
      "            root: typing.Union[str, os.PathLike],\n",
      "            class_to_idx: typing.Optional[typing.Dict[str, int]] = None,\n",
      "            transform: typing.Optional[typing.Callable] = None,\n",
      "            target_transform: typing.Optional[typing.Callable] = None,\n",
      "            loader: typing.Callable[[str], typing.Any] = default_loader,\n",
      "            is_valid_file: typing.Optional[typing.Callable[[str], bool]] = None,\n",
      "    ):\n",
      "        self.class_to_idx = class_to_idx\n",
      "        super(ImageFolder, self).__init__(root, transform, target_transform, loader, is_valid_file)\n",
      "\n",
      "    def _find_classes(self, directory: str) -> typing.Tuple[typing.List[str], typing.Dict[str, int]]:\n",
      "        \"\"\"\n",
      "        Finds the class folders in a dataset.\n",
      "\n",
      "        Args:\n",
      "            directory (string): Root directory path.\n",
      "\n",
      "        Returns:\n",
      "            tuple: (classes, class_to_idx) where classes are relative to (dir), and class_to_idx is a dictionary.\n",
      "\n",
      "        Ensures:\n",
      "            No class is a subdirectory of another.\n",
      "        \"\"\"\n",
      "        classes = [d.name for d in os.scandir(directory) if d.is_dir()]\n",
      "        classes.sort()\n",
      "        try:\n",
      "            class_to_idx = self.class_to_idx\n",
      "        except AttributeError:\n",
      "            class_to_idx = None\n",
      "        if class_to_idx is None:\n",
      "            class_to_idx = self.class_to_idx or {cls_name: i for i, cls_name in enumerate(classes)}\n",
      "        return classes, class_to_idx\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dataset Class Source Code\n",
    "\n",
    "print(inspect.getsource(data_prep_utils.dataset.ImageWithPandas))\n",
    "print(inspect.getsource(data_prep_utils.dataset.ImageFolder))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "data_transform = torchvision.transforms.Compose([\n",
    "    # torchvision.transforms.RandomResizedCrop(26),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=[0.45],std=[0.225])\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "\n",
    "def get_train_transforms():\n",
    "    return A.Compose(\n",
    "        [\n",
    "            # A.RandomSizedCrop(min_max_height=(1024, 1024), height=1024, width=1024, p=0.5),\n",
    "            A.OneOf([\n",
    "                A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit= 0.2,\n",
    "                                     val_shift_limit=0.2, p=0.9),\n",
    "                A.RandomBrightnessContrast(brightness_limit=0.2,\n",
    "                                           contrast_limit=0.2, p=0.9),\n",
    "            ],p=0.9),\n",
    "            # A.ToGray(p=0.01),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            # A.Resize(height=512, width=512, p=1),\n",
    "            # A.Cutout(num_holes=8, max_h_size=64, max_w_size=64, fill_value=0, p=0.5),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ],\n",
    "        p=1.0,\n",
    "        bbox_params=A.BboxParams(\n",
    "            format='pascal_voc',\n",
    "            min_area=0,\n",
    "            min_visibility=0,\n",
    "            label_fields=['labels']\n",
    "        )\n",
    "    )\n",
    "\n",
    "def get_valid_transforms():\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.Resize(height=512, width=512, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ],\n",
    "        p=1.0,\n",
    "        bbox_params=A.BboxParams(\n",
    "            format='pascal_voc',\n",
    "            min_area=0,\n",
    "            min_visibility=0,\n",
    "            label_fields=['labels']\n",
    "        )\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "classification_dataset_1 = rsna_pneumonia_detection_challenge.torch_classification_dataset(data_transform)\n",
    "\n",
    "classification_dataset_2 = covid_19_radiography_dataset.torch_classification_dataset(data_transform)\n",
    "\n",
    "detection_dataset = rsna_pneumonia_detection_challenge.torch_detection_dataset(get_train_transforms())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Make data loader from dataset\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_loader_cls_1 = torch.utils.data.DataLoader(classification_dataset_1,\n",
    "                                              batch_size=batch_size, shuffle=True,\n",
    "                                              num_workers=2)\n",
    "train_loader_cls_2 = torch.utils.data.DataLoader(classification_dataset_2,\n",
    "                                              batch_size=batch_size, shuffle=True,\n",
    "                                              num_workers=2)\n",
    "\n",
    "train_loader_det_1 = torch.utils.data.DataLoader(\n",
    "        detection_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        # pin_memory=False,\n",
    "        num_workers=2\n",
    ")\n",
    "\n",
    "train_loaders = [train_loader_cls_1, train_loader_cls_2, train_loader_det_1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Design Model Architecture\n",
    "* Base Model: EfficientNet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# from efficientnet_pytorch import EfficientNet\n",
    "#\n",
    "# # Shared Feature Extractor\n",
    "# feature_extractor_depth = 10\n",
    "# feature_extractor = EfficientNet.from_pretrained(f'efficientnet-b{feature_extractor_depth}', include_top=False)\n",
    "# feature_extractor.out_channels = feature_extractor._bn1.num_features\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# class Classifier(nn.Module):\n",
    "#\n",
    "#     def __init__(self, backbone, num_classes, out_channels=None, dropout_rate=0.2):\n",
    "#         super().__init__()\n",
    "#         out_channels = out_channels or backbone.out_channels\n",
    "#         self.feature_extractor = backbone\n",
    "#         self.dropout = nn.Dropout(dropout_rate)\n",
    "#         self.fc = nn.Linear(out_channels, num_classes)\n",
    "#\n",
    "#     def forward(self, x):\n",
    "#         x = self.feature_extractor(x)\n",
    "#         x = self.dropout(x)\n",
    "#         x = self.fc(x)\n",
    "#         return x\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<timm.models.features.FeatureInfo object at 0x157895040>\n"
     ]
    }
   ],
   "source": [
    "detection_config = get_efficientdet_config('tf_efficientdet_d4')\n",
    "detection_config.update(num_classes=4)\n",
    "\n",
    "feature_backbone = tf_efficientnet_b4(\n",
    "    pretrained=False,  # FIXME\n",
    "    features_only=True,\n",
    "    out_indices=(2, 3, 4),\n",
    "    in_chans = 1,\n",
    "    **detection_config.backbone_args\n",
    ")\n",
    "print(feature_backbone.feature_info)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "\n",
    "class EfficientDet(nn.Module):\n",
    "\n",
    "    def __init__(self, config, backbone):\n",
    "        super(EfficientDet, self).__init__()\n",
    "        self.config = config\n",
    "        self.backbone = backbone\n",
    "        self.fpn = BiFpn(self.config, backbone.feature_info.get_dicts(keys=['num_chs', 'reduction']))\n",
    "        self.class_net = HeadNet(self.config, num_outputs=config.num_classes)  # num_classes\n",
    "        self.box_net = HeadNet(self.config, num_outputs=4)\n",
    "\n",
    "        for n, m in self.named_modules():\n",
    "            if 'backbone' not in n:\n",
    "                _init_weight(m, n)\n",
    "\n",
    "    @torch.jit.ignore()\n",
    "    def toggle_head_bn_level_first(self):\n",
    "        \"\"\" Toggle the head batchnorm layers between being access with feature_level first vs repeat\n",
    "        \"\"\"\n",
    "        self.class_net.toggle_bn_level_first()\n",
    "        self.box_net.toggle_bn_level_first()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.fpn(x)\n",
    "        x_class = self.class_net(x)\n",
    "        x_box = self.box_net(x)\n",
    "        return x_class, x_box\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def detect(self, x):\n",
    "        return self.forward(x)[1]\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def classify(self, x):\n",
    "        return self.forward(x)[0]\n",
    "\n",
    "\n",
    "net = EfficientDet(detection_config, feature_backbone)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "plt.ioff()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "from train_utils import Trainer, MultipleOptimizerHandler\n",
    "\n",
    "\n",
    "class AdvancedFitter(Trainer):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            model,\n",
    "            config,\n",
    "            opt_c,\n",
    "            opt_d,\n",
    "            epoch: int,\n",
    "            train_iter = None,\n",
    "            val_iter = None,\n",
    "            test_iter = None,\n",
    "            snapshot_dir = None,\n",
    "            verbose: bool = True,\n",
    "            timer: bool = False,\n",
    "            log_interval = 20,\n",
    "    ) -> None:\n",
    "\n",
    "        self.train_iter = train_iter\n",
    "        self.val_iter = val_iter\n",
    "        self.test_iter = test_iter\n",
    "\n",
    "        self.model = model\n",
    "        self.config = config\n",
    "        self.criterion = DetBenchTrain(model, config)\n",
    "        self.optimizer = MultipleOptimizerHandler({'c': opt_c, 'd': opt_d})\n",
    "        self.total_epoch: int = epoch\n",
    "        self.snapshot_dir: pathlib.Path = pathlib.Path(snapshot_dir).resolve()\n",
    "        self.verbose: bool = verbose\n",
    "        self.use_timer: bool = timer\n",
    "        self.log_interval: int = log_interval\n",
    "        self.save_and_load: bool = bool(snapshot_dir is not None and val_iter is not None)\n",
    "\n",
    "        # FIXME\n",
    "        # self.train_batch_size: int = train_iter.batch_size\n",
    "        # self.train_loader_length: int = len(train_iter)\n",
    "        # self.train_dataset_length: int = len(getattr(train_iter, 'dataset', train_iter))\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # Do not set attribute of instance.\n",
    "        print(\"Advanced Fitter Initialized.\")\n",
    "\n",
    "    def _train(self):\n",
    "\n",
    "        self._require_context()\n",
    "\n",
    "        self.model.train()\n",
    "\n",
    "        verbose = self.verbose\n",
    "        log_interval = self.log_interval\n",
    "\n",
    "        total_loss = total_accuracy = 0.\n",
    "        total_batch = 0\n",
    "        det_loss = 0.\n",
    "        det_batch = 0\n",
    "\n",
    "        datasets = self.train_iter\n",
    "\n",
    "        for data in datasets:\n",
    "\n",
    "            whole = len(data)\n",
    "            for iteration, (images, targets) in enumerate(data, 1):\n",
    "\n",
    "                if isinstance(targets, dict):\n",
    "                    l = self._train_detection(images, targets)\n",
    "                    det_loss += l; det_batch += 1\n",
    "                    if iteration % log_interval == 0 and verbose:\n",
    "                        self._log_train_doing(l, iteration, whole)\n",
    "\n",
    "                else:\n",
    "                    l, a = self._train_classification(images, targets)\n",
    "                    total_loss += l; total_accuracy += a; total_batch += 1\n",
    "                    if iteration % log_interval == 0 and verbose:\n",
    "                        self._log_train_doing(l, iteration, whole)\n",
    "\n",
    "        avg_loss = total_loss / total_batch\n",
    "        avg_accuracy = total_accuracy / total_batch\n",
    "\n",
    "        self._log_train_done(avg_loss, avg_accuracy)\n",
    "\n",
    "        det_avg_loss = det_loss / det_batch\n",
    "\n",
    "        self._log_train_done(det_avg_loss)\n",
    "\n",
    "        return avg_loss, avg_accuracy\n",
    "\n",
    "    def _train_classification(self, images, targets):\n",
    "\n",
    "        images = self._to_apply_tensor(images).float()\n",
    "        prediction = self.model(images)[0]\n",
    "        loss = F.binary_cross_entropy_with_logits(prediction, targets)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            l = loss.item()\n",
    "            a = torch.eq(torch.argmax(prediction, 1), targets).float().mean().item()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer = self.optimizer['c']\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        return l, a\n",
    "\n",
    "    def _train_detection(self, images, targets):\n",
    "\n",
    "        images = self._to_apply_tensor(images).float()\n",
    "        boxes = [self._to_apply_tensor(target['boxes']).float() for target in targets]\n",
    "        labels = [self._to_apply_tensor(target['labels']).float() for target in targets]\n",
    "\n",
    "        loss, _, _ = self.criterion(images, boxes, labels)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer = self.optimizer['d']\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        return loss.item()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _evaluate(self, *, test=False):\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        datasets = self.test_iter if test else self.val_iter\n",
    "\n",
    "        total_loss = total_accuracy = 0.\n",
    "        total_batch = 0\n",
    "        det_loss = 0.\n",
    "        det_batch = 0\n",
    "\n",
    "        for data in datasets:\n",
    "\n",
    "            for images, targets in data:\n",
    "\n",
    "                if isinstance(targets, dict):\n",
    "                    l = self._eval_detection(images, targets)\n",
    "                    det_loss += l; det_batch += 1\n",
    "\n",
    "                else:\n",
    "                    l, a = self._eval_classification(images, targets)\n",
    "                    total_loss += l; total_accuracy += a; total_batch += 1\n",
    "\n",
    "        avg_loss = total_loss / total_batch\n",
    "        avg_accuracy = total_accuracy / total_batch\n",
    "\n",
    "        self._log_eval(avg_loss, avg_accuracy, test=test)\n",
    "\n",
    "        det_avg_loss = det_loss / det_batch\n",
    "\n",
    "        self._log_eval(det_avg_loss, test=test)\n",
    "\n",
    "        return avg_loss, avg_accuracy\n",
    "\n",
    "    def _eval_classification(self, images, targets):\n",
    "\n",
    "        images = self._to_apply_tensor(images).float()\n",
    "        prediction = self.model(images)[0]\n",
    "        loss = F.binary_cross_entropy_with_logits(prediction, targets)\n",
    "\n",
    "        l = loss.item()\n",
    "        a = torch.eq(torch.argmax(prediction, 1), targets).float().mean().item()\n",
    "\n",
    "        return l, a\n",
    "\n",
    "    def _eval_detection(self, images, targets):\n",
    "\n",
    "        images = self._to_apply_tensor(images).float()\n",
    "        boxes = [self._to_apply_tensor(target['boxes']).float() for target in targets]\n",
    "        labels = [self._to_apply_tensor(target['labels']).float() for target in targets]\n",
    "\n",
    "        loss, _, _ = self.criterion(images, boxes, labels)\n",
    "\n",
    "        return loss.item()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "num_epochs = 3\n",
    "\n",
    "lr = 0.0002\n",
    "\n",
    "optimizer = torch.optim.AdamW(net.parameters(), lr=lr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advanced Fitter Initialized.\n",
      "\n",
      "<Start Learning> \t\t\t\tTotal 3 epochs\n",
      "\n",
      "Epoch 1\n"
     ]
    }
   ],
   "source": [
    "fitter = AdvancedFitter(\n",
    "    net, detection_config, optimizer, optimizer,\n",
    "    num_epochs,\n",
    "    train_iter = train_loaders,\n",
    "    val_iter = train_loaders,\n",
    "    snapshot_dir = 'snapshots',\n",
    "    verbose=True,\n",
    "    timer=True,\n",
    ")\n",
    "fitter.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "with fitter:\n",
    "    fitter.run()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}