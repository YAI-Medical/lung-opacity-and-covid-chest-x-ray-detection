{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Mounting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Check, with local module, whether runtime is colaboratory\n",
    "\n",
    "try:  # local runtime\n",
    "    import library_check\n",
    "except ImportError:  # colab runtime\n",
    "    library_check = None\n",
    "    from google.colab import drive  # NOQA\n",
    "    drive.mount('/content/drive')  # NOQA\n",
    "    colaboratory = True\n",
    "else:\n",
    "    colaboratory = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runtime Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS version: \t\tmacOS-11.5.2-arm64-arm-64bit\n",
      "Python version:\t\t3.8.10 | packaged by conda-forge | (default, May 11 2021, 06:27:18) \n",
      "[Clang 11.1.0 ]\n"
     ]
    }
   ],
   "source": [
    "# System Information\n",
    "\n",
    "import sys\n",
    "import platform\n",
    "print(f\"OS version: \\t\\t{platform.platform()}\\n\"\n",
    "      f\"Python version:\\t\\t{sys.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required libraries are installed.\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "\n",
    "if colaboratory:  # colab runtime\n",
    "    # !pip install pydicom albumentations==0.4.6 efficientnet_pytorch effdet\n",
    "    # !pip install mxnet-cu101==1.7.0 d2l==0.16.6\n",
    "    !git clone https://github.com/kdha0727/lung-opacity-and-covid-chest-x-ray-detection/\n",
    "    %cd lung-opacity-and-covid-chest-x-ray-detection\n",
    "    !pip install -r requirements.txt\n",
    "    import library_check\n",
    "    library_check.check()\n",
    "    import data_prep_utils\n",
    "    root = \"/content/drive/Shareddrives/2021 하계 SAT/\"\n",
    "    data_prep_utils.set_root(root)\n",
    "else:  # local runtime\n",
    "    library_check.check()\n",
    "    import data_prep_utils\n",
    "data_prep_utils.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# After all installation, import all libraries used.\n",
    "\n",
    "import inspect\n",
    "import random\n",
    "import pydicom as dcm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import seaborn as sns\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch\n",
    "import torchvision\n",
    "import torchsummary\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "\n",
    "from timm.models.efficientnet import tf_efficientnet_b4\n",
    "from effdet import get_efficientdet_config, DetBenchTrain\n",
    "from effdet.efficientdet import HeadNet, BiFpn, _init_weight\n",
    "\n",
    "from skimage import io, transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# And, import custom-defined Lazy Data Wrappers and Utilities\n",
    "\n",
    "from data_prep_utils import covid_19_radiography_dataset\n",
    "from data_prep_utils import rsna_pneumonia_detection_challenge\n",
    "\n",
    "from data_prep_utils.dataset import pil_loader, dicom_loader\n",
    "import train_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis and Processing\n",
    "\n",
    "* Note: All preprocessing processes are modularized as \"Data Wrapper\" package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Class Information**\n",
    "* Normal: 0\n",
    "* Lung Opacity: 1\n",
    "* COVID-19: 2\n",
    "* Viral Pneumonia: 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: [\n",
      "\t('Normal', 0)\n",
      "\t('Lung_Opacity', 1)\n",
      "\t('COVID', 2)\n",
      "\t('Viral Pneumonia', 3) \n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print('\\n\\t'.join(map(str, ['Labels: [', *covid_19_radiography_dataset.class_to_idx.items()])), '\\n]')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling via PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class ImageWithPandas(VisionDataset):\n",
      "    \"\"\"A generic data loader where the image path and label is given as pandas DataFrame.\n",
      "\n",
      "    Args:\n",
      "        dataframe (pandas.DataFrame): A data table that contains image path, target class,\n",
      "            and extra outputs.\n",
      "        label_id (string): Data frame`s image path label string.\n",
      "        label_target (string): Data frame`s target class label string.\n",
      "        label_extras (tuple[string] or string, optional): Data frame`s label that will\n",
      "            be used for extra outputs.\n",
      "        root (string, optional): Root directory path. Use unless data frame`s column\n",
      "            contains file folders.\n",
      "        extension (string, optional): An extension that will be concatenated after\n",
      "            image file name. Use unless data frame`s column contains extension.\n",
      "        class_to_idx (dict[str, int], optional): A mapping table that converts class\n",
      "            label string into integer value. If not given, sorted index value will\n",
      "            be used as class integer value.\n",
      "        transform (callable, optional): A function/transform that takes in an image\n",
      "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "        target_transform (callable, optional): A function/transform that takes in the\n",
      "            target and transforms it.\n",
      "        extras_transform (callable, optional): A function/transform that takes in the\n",
      "            extra outputs and transforms it.\n",
      "        loader (callable, optional): A function to load an image given its path.\n",
      "\n",
      "     Attributes:\n",
      "        classes (list): List of the class names sorted alphabetically.\n",
      "        class_to_idx (dict): Dict with items (class_name, class_index).\n",
      "        samples (list): List of (sample path, class_index) tuples\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(\n",
      "            self,\n",
      "            dataframe: pd.DataFrame,\n",
      "            label_id: str,\n",
      "            label_target: str,\n",
      "            root: typing.Optional[typing.Union[str, os.PathLike]] = None,\n",
      "            extension: typing.Optional[str] = None,\n",
      "            class_to_idx: typing.Optional[typing.Dict[typing.Any, int]] = None,\n",
      "            transform: typing.Optional[typing.Callable] = None,\n",
      "            target_transform: typing.Optional[typing.Callable] = None,\n",
      "            extras_transform: typing.Optional[typing.Callable] = None,\n",
      "            loader: typing.Callable[[str], typing.Any] = default_loader,\n",
      "    ) -> None:\n",
      "\n",
      "        super(ImageWithPandas, self).__init__(root, None, transform, target_transform)\n",
      "\n",
      "        self.extras_transform = extras_transform\n",
      "        self.loader = loader\n",
      "        self.label_id = label_id\n",
      "        self.label_target = label_target\n",
      "\n",
      "        labels = [label_id, label_target]\n",
      "\n",
      "        samples = dataframe[labels].copy(deep=True)\n",
      "\n",
      "        assert extension.startswith('.') or extension is None\n",
      "        if root is not None:\n",
      "            root = os.path.expanduser(root)\n",
      "        if root is not None or extension is not None:\n",
      "            samples[label_id] = samples[label_id].map(\n",
      "                (lambda x: os.path.join(root, x + extension or ''))\n",
      "                if root is not None else (lambda x: x + extension)\n",
      "            )\n",
      "\n",
      "        classes = sorted(samples[label_target].unique())\n",
      "        if class_to_idx is None:\n",
      "            class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
      "        samples[label_target] = samples[label_target].map(lambda x: class_to_idx[x])\n",
      "\n",
      "        samples = samples.drop_duplicates()\n",
      "\n",
      "        self.ids = tuple(samples[label_id].drop_duplicates())\n",
      "        self.samples = samples\n",
      "        self.classes = classes\n",
      "        self.class_to_idx = class_to_idx\n",
      "        self.num_classes = len(class_to_idx)\n",
      "\n",
      "    def __len__(self):\n",
      "        return len(self.ids)\n",
      "\n",
      "    def __getitem__(self, index: int) -> ...:\n",
      "        image_id = self.ids[index]\n",
      "        row = self.samples[self.samples[self.label_id] == image_id]\n",
      "        path, target = row[self.label_id], row[self.label_target]\n",
      "        sample = self.loader(path.item())\n",
      "        if self.transform is not None:\n",
      "            sample = self.transform(sample)\n",
      "        if self.target_transform is not None:\n",
      "            target = self.target_transform(target)\n",
      "        else:\n",
      "            target = np.array(target)\n",
      "        return sample, target\n",
      "\n",
      "class ImageFolder(_ImageFolder):\n",
      "    \"\"\"A generic data loader where the images are arranged in root folder.\n",
      "\n",
      "    Args:\n",
      "        root (string): Root directory path.\n",
      "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "        target_transform (callable, optional): A function/transform that takes in the\n",
      "            target and transforms it.\n",
      "        loader (callable, optional): A function to load an image given its path.\n",
      "        is_valid_file (callable, optional): A function that takes path of an Image file\n",
      "            and check if the file is a valid file (used to check of corrupt files)\n",
      "\n",
      "     Attributes:\n",
      "        classes (list): List of the class names sorted alphabetically.\n",
      "        class_to_idx (dict): Dict with items (class_name, class_index).\n",
      "        imgs (list): List of (image path, class_index) tuples\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(\n",
      "            self,\n",
      "            root: typing.Union[str, os.PathLike],\n",
      "            class_to_idx: typing.Optional[typing.Dict[str, int]] = None,\n",
      "            transform: typing.Optional[typing.Callable] = None,\n",
      "            target_transform: typing.Optional[typing.Callable] = None,\n",
      "            loader: typing.Callable[[str], typing.Any] = default_loader,\n",
      "            is_valid_file: typing.Optional[typing.Callable[[str], bool]] = None,\n",
      "    ):\n",
      "        self.class_to_idx = class_to_idx\n",
      "        super(ImageFolder, self).__init__(root, transform, target_transform, loader, is_valid_file)\n",
      "\n",
      "    def _find_classes(self, directory: str) -> typing.Tuple[typing.List[str], typing.Dict[str, int]]:\n",
      "        \"\"\"\n",
      "        Finds the class folders in a dataset.\n",
      "\n",
      "        Args:\n",
      "            directory (string): Root directory path.\n",
      "\n",
      "        Returns:\n",
      "            tuple: (classes, class_to_idx) where classes are relative to (dir), and class_to_idx is a dictionary.\n",
      "\n",
      "        Ensures:\n",
      "            No class is a subdirectory of another.\n",
      "        \"\"\"\n",
      "        classes = [d.name for d in os.scandir(directory) if d.is_dir()]\n",
      "        classes.sort()\n",
      "        try:\n",
      "            class_to_idx = self.class_to_idx\n",
      "        except AttributeError:\n",
      "            class_to_idx = None\n",
      "        if class_to_idx is None:\n",
      "            class_to_idx = self.class_to_idx or {cls_name: i for i, cls_name in enumerate(classes)}\n",
      "        return classes, class_to_idx\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dataset Class Source Code\n",
    "\n",
    "print(inspect.getsource(data_prep_utils.dataset.ImageWithPandas))\n",
    "print(inspect.getsource(data_prep_utils.dataset.ImageFolder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomResizedCrop(256),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=[0.45],std=[0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_train_transforms():\n",
    "    return A.Compose(\n",
    "        [\n",
    "            # A.RandomSizedCrop(min_max_height=(1024, 1024), height=1024, width=1024, p=0.5),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.2,\n",
    "                                       contrast_limit=0.2, p=0.9),\n",
    "            # A.ToGray(p=0.01),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.Resize(height=256, width=256, p=1),\n",
    "            # A.Cutout(num_holes=8, max_h_size=64, max_w_size=64, fill_value=0, p=0.5),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ],\n",
    "        p=1.0,\n",
    "        bbox_params=A.BboxParams(\n",
    "            format='pascal_voc',\n",
    "            min_area=0,\n",
    "            min_visibility=0,\n",
    "            label_fields=['labels']\n",
    "        )\n",
    "    )\n",
    "\n",
    "def get_valid_transforms():\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.Resize(height=256, width=256, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ],\n",
    "        p=1.0,\n",
    "        bbox_params=A.BboxParams(\n",
    "            format='pascal_voc',\n",
    "            min_area=0,\n",
    "            min_visibility=0,\n",
    "            label_fields=['labels']\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "classification_dataset_1 = rsna_pneumonia_detection_challenge.torch_classification_dataset(data_transform)\n",
    "\n",
    "classification_dataset_2 = covid_19_radiography_dataset.torch_classification_dataset(data_transform)\n",
    "\n",
    "detection_dataset = rsna_pneumonia_detection_challenge.torch_detection_dataset(get_train_transforms())\n",
    "\n",
    "\n",
    "cls_dset = torch.utils.data.ConcatDataset([\n",
    "    classification_dataset_1,\n",
    "    classification_dataset_2\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Make data loader from dataset\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_loader_cls = torch.utils.data.DataLoader(cls_dset,\n",
    "                                              batch_size=batch_size, shuffle=True,\n",
    "                                              num_workers=2)\n",
    "\n",
    "train_loader_cls_1 = torch.utils.data.DataLoader(classification_dataset_1,\n",
    "                                              batch_size=batch_size, shuffle=True,\n",
    "                                              num_workers=2)\n",
    "train_loader_cls_2 = torch.utils.data.DataLoader(classification_dataset_2,\n",
    "                                              batch_size=batch_size, shuffle=True,\n",
    "                                              num_workers=2)\n",
    "\n",
    "train_loader_det_1 = torch.utils.data.DataLoader(\n",
    "        detection_dataset,\n",
    "        batch_size=2,\n",
    "        shuffle=True,\n",
    "        # pin_memory=False,\n",
    "        num_workers=2\n",
    ")\n",
    "\n",
    "train_loader_det_1_prime = rsna_pneumonia_detection_challenge.torch_detection_dataset(\n",
    "    get_train_transforms(),\n",
    "        batch_size=4,\n",
    "        shuffle=True,\n",
    "        # pin_memory=False,\n",
    "        num_workers=2\n",
    ")\n",
    "\n",
    "train_loaders = [\n",
    "    # train_loader_cls_1, train_loader_cls_2,\n",
    "    train_loader_det_1_prime\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design Model Architecture\n",
    "* Base Model: EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "from efficientnet_pytorch.utils import get_model_params\n",
    "\n",
    "# Shared Feature Extractor\n",
    "feature_extractor_depth = 4\n",
    "# FIXME -> from pretrained\n",
    "feature_extracor_model_name = f'efficientnet-b{feature_extractor_depth}'\n",
    "feature_extractor = EfficientNet.from_name(feature_extracor_model_name, include_top=False, image_size=256)\n",
    "feature_extractor._change_in_channels(1)\n",
    "feature_extractor.out_channels = feature_extractor._bn1.num_features\n",
    "\n",
    "# # Get stem static or dynamic convolution depending on image size\n",
    "# blocks_args, global_params = get_model_params(feature_extracor_model_name, {})\n",
    "# global_params.image_size = 256\n",
    "#\n",
    "# # Stem\n",
    "# in_channels = 3  # rgb\n",
    "# out_channels = round_filters(32, global_params)  # number of output channels\n",
    "# self._conv_stem = Conv2d(in_channels, out_channels, kernel_size=3, stride=2, bias=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "FasterRCNN(\n  (transform): GeneralizedRCNNTransform(\n      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n  )\n  (backbone): EfficientNet(\n    (_conv_stem): Conv2dStaticSamePadding(\n      3, 48, kernel_size=(3, 3), stride=(2, 2), bias=False\n      (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n    )\n    (_bn0): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n    (_blocks): ModuleList(\n      (0): MBConvBlock(\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          48, 48, kernel_size=(3, 3), stride=[1, 1], groups=48, bias=False\n          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n        )\n        (_bn1): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          48, 12, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          12, 48, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (1): MBConvBlock(\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n        )\n        (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          24, 6, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          6, 24, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (2): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False\n          (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n        )\n        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          144, 6, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          6, 144, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (3): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n        )\n        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          192, 8, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          8, 192, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (4): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n        )\n        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          192, 8, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          8, 192, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (5): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n        )\n        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          192, 8, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          8, 192, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (6): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False\n          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n        )\n        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          192, 8, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          8, 192, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          192, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (7): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n        )\n        (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          336, 14, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          14, 336, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (8): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n        )\n        (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          336, 14, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          14, 336, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (9): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n        )\n        (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          336, 14, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          14, 336, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (10): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          336, 336, kernel_size=(3, 3), stride=[2, 2], groups=336, bias=False\n          (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n        )\n        (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          336, 14, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          14, 336, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          336, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (11): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n        )\n        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          672, 28, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          28, 672, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (12): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n        )\n        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          672, 28, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          28, 672, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (13): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n        )\n        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          672, 28, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          28, 672, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (14): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n        )\n        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          672, 28, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          28, 672, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (15): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n        )\n        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          672, 28, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          28, 672, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (16): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          672, 672, kernel_size=(5, 5), stride=[1, 1], groups=672, bias=False\n          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n        )\n        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          672, 28, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          28, 672, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (17): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n        )\n        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          960, 40, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          40, 960, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (18): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n        )\n        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          960, 40, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          40, 960, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (19): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n        )\n        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          960, 40, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          40, 960, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (20): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n        )\n        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          960, 40, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          40, 960, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (21): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n        )\n        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          960, 40, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          40, 960, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (22): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          960, 960, kernel_size=(5, 5), stride=[2, 2], groups=960, bias=False\n          (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n        )\n        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          960, 40, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          40, 960, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          960, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (23): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n        )\n        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (24): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n        )\n        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (25): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n        )\n        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (26): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n        )\n        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (27): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n        )\n        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (28): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n        )\n        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (29): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n        )\n        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (30): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          1632, 1632, kernel_size=(3, 3), stride=[1, 1], groups=1632, bias=False\n          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n        )\n        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          1632, 448, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(448, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (31): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          448, 2688, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(2688, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          2688, 2688, kernel_size=(3, 3), stride=(1, 1), groups=2688, bias=False\n          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n        )\n        (_bn1): BatchNorm2d(2688, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          2688, 112, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          112, 2688, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          2688, 448, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(448, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n    )\n    (_conv_head): Conv2dStaticSamePadding(\n      448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False\n      (static_padding): Identity()\n    )\n    (_bn1): BatchNorm2d(1792, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n    (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n    (_swish): MemoryEfficientSwish()\n  )\n  (rpn): RegionProposalNetwork(\n    (anchor_generator): AnchorGenerator()\n    (head): RPNHead(\n      (conv): Conv2d(1792, 1792, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (cls_logits): Conv2d(1792, 12, kernel_size=(1, 1), stride=(1, 1))\n      (bbox_pred): Conv2d(1792, 48, kernel_size=(1, 1), stride=(1, 1))\n    )\n  )\n  (roi_heads): RoIHeads(\n    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n    (box_head): TwoMLPHead(\n      (fc6): Linear(in_features=87808, out_features=1024, bias=True)\n      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n    )\n    (box_predictor): FastRCNNPredictor(\n      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n      (bbox_pred): Linear(in_features=1024, out_features=16, bias=True)\n    )\n  )\n)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Classifier(nn.Module):\n",
    "\n",
    "    def __init__(self, backbone, num_classes, out_channels=None, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        out_channels = out_channels or backbone.out_channels\n",
    "        self.feature_extractor = backbone\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(out_channels, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.flatten(x)\n",
    "        print(x.shape)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# model = Classifier(feature_extractor, 4)\n",
    "\n",
    "from models import get_full_network\n",
    "\n",
    "model = get_full_network(\n",
    "    pretrained_backbone=colaboratory  # FIXME: remove this line\n",
    ").float()\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "lr = 0.0002\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "dset = ConcatDataset([\n",
    "    classification_dataset_1,\n",
    "    classification_dataset_2\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advanced Fitter Initialized.\n",
      "\n",
      "<Start Learning> \t\t\t\tTotal 3 epochs\n",
      "\n",
      "Epoch 1\n",
      "[Train]\t Progress: 11/1505 (00.73%), \tLoss: 11.366343 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <Finalize object, dead>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/python-dl/lib/python3.8/multiprocessing/util.py\", line 213, in __call__\n",
      "    try:\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/python-dl/lib/python3.8/site-packages/torch/utils/data/_utils/signal_handling.py\", line 66, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 3967) is killed by signal: Interrupt: 2. \n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x120730160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/python-dl/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1324, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/python-dl/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1297, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/python-dl/lib/python3.8/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/python-dl/lib/python3.8/multiprocessing/popen_fork.py\", line 44, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/python-dl/lib/python3.8/multiprocessing/connection.py\", line 931, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/python-dl/lib/python3.8/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x120730160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/python-dl/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1324, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/python-dl/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1297, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/python-dl/lib/python3.8/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/python-dl/lib/python3.8/multiprocessing/popen_fork.py\", line 44, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/python-dl/lib/python3.8/multiprocessing/connection.py\", line 931, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/python-dl/lib/python3.8/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "from train_utils import AdvancedFitter\n",
    "\n",
    "fitter = AdvancedFitter(\n",
    "    model, optimizer,\n",
    "    num_epochs,\n",
    "    train_iter = train_loaders,\n",
    "    val_iter = train_loaders,\n",
    "    snapshot_dir = 'snapshots',\n",
    "    verbose=True,\n",
    "    timer=True,\n",
    "    log_interval=1,\n",
    ")\n",
    "fitter.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "with fitter:\n",
    "    fitter.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def get_next():\n",
    "    try:\n",
    "        iterator = iter(train_loaders[0])\n",
    "        return next(iterator)\n",
    "    except RuntimeError:  # 오류안뜰때까지 뽑아보자\n",
    "        return get_next()\n",
    "\n",
    "    \n",
    "nxt = get_next()\n",
    "print({k: v.shape for k, v in nxt.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "next(iter(train_loaders[0]))['image'].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}