{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Mounting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Check, with local module, whether runtime is colaboratory\n",
    "\n",
    "try:  # local runtime\n",
    "    import library_check\n",
    "except ImportError:  # colab runtime\n",
    "    library_check = None\n",
    "    from google.colab import drive  # NOQA\n",
    "    drive.mount('/content/drive')  # NOQA\n",
    "    colaboratory = True\n",
    "else:\n",
    "    colaboratory = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runtime Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS version: \t\tmacOS-11.5.2-arm64-arm-64bit\n",
      "Python version:\t\t3.8.10 | packaged by conda-forge | (default, May 11 2021, 06:27:18) \n",
      "[Clang 11.1.0 ]\n"
     ]
    }
   ],
   "source": [
    "# System Information\n",
    "\n",
    "import sys\n",
    "import platform\n",
    "print(f\"OS version: \\t\\t{platform.platform()}\\n\"\n",
    "      f\"Python version:\\t\\t{sys.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required libraries are installed.\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "\n",
    "if colaboratory:  # colab runtime\n",
    "    # !pip install pydicom albumentations==0.4.6 efficientnet_pytorch effdet\n",
    "    # !pip install mxnet-cu101==1.7.0 d2l==0.16.6\n",
    "    !git clone https://github.com/kdha0727/lung-opacity-and-covid-chest-x-ray-detection/\n",
    "    %cd lung-opacity-and-covid-chest-x-ray-detection\n",
    "    !pip install -r requirements.txt\n",
    "    import library_check\n",
    "    library_check.check()\n",
    "    import data_prep_utils\n",
    "    root = \"/content/drive/Shareddrives/2021 하계 SAT/\"\n",
    "    data_prep_utils.set_root(root)\n",
    "else:  # local runtime\n",
    "    library_check.check()\n",
    "    import data_prep_utils\n",
    "data_prep_utils.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# After all installation, import all libraries used.\n",
    "\n",
    "import inspect\n",
    "import random\n",
    "import pydicom as dcm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch\n",
    "import torchvision\n",
    "import torchsummary\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "from timm.models.efficientnet import tf_efficientnet_b4\n",
    "from effdet import get_efficientdet_config, DetBenchTrain\n",
    "from effdet.efficientdet import HeadNet, BiFpn, _init_weight\n",
    "\n",
    "from skimage import io, transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# And, import custom-defined Lazy Data Wrappers and Utilities\n",
    "\n",
    "from data_prep_utils import covid_19_radiography_dataset\n",
    "from data_prep_utils import rsna_pneumonia_detection_challenge\n",
    "\n",
    "from data_prep_utils.dataset import pil_loader, dicom_loader\n",
    "import train_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis and Processing\n",
    "\n",
    "* Note: All preprocessing processes are modularized as \"Data Wrapper\" package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Class Information**\n",
    "* Normal: 0\n",
    "* Lung Opacity: 1\n",
    "* COVID-19: 2\n",
    "* Viral Pneumonia: 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: [\n",
      "\t('Normal', 0)\n",
      "\t('Lung_Opacity', 1)\n",
      "\t('COVID', 2)\n",
      "\t('Viral Pneumonia', 3) \n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print('\\n\\t'.join(map(str, ['Labels: [', *covid_19_radiography_dataset.class_to_idx.items()])), '\\n]')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling via PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class ImageWithPandas(VisionDataset):\n",
      "    \"\"\"A generic data loader where the image path and label is given as pandas DataFrame.\n",
      "\n",
      "    Args:\n",
      "        dataframe (pandas.DataFrame): A data table that contains image path, target class,\n",
      "            and extra outputs.\n",
      "        label_id (string): Data frame`s image path label string.\n",
      "        label_target (string): Data frame`s target class label string.\n",
      "        label_extras (tuple[string] or string, optional): Data frame`s label that will\n",
      "            be used for extra outputs.\n",
      "        root (string, optional): Root directory path. Use unless data frame`s column\n",
      "            contains file folders.\n",
      "        extension (string, optional): An extension that will be concatenated after\n",
      "            image file name. Use unless data frame`s column contains extension.\n",
      "        class_to_idx (dict[str, int], optional): A mapping table that converts class\n",
      "            label string into integer value. If not given, sorted index value will\n",
      "            be used as class integer value.\n",
      "        transform (callable, optional): A function/transform that takes in an image\n",
      "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "        target_transform (callable, optional): A function/transform that takes in the\n",
      "            target and transforms it.\n",
      "        extras_transform (callable, optional): A function/transform that takes in the\n",
      "            extra outputs and transforms it.\n",
      "        loader (callable, optional): A function to load an image given its path.\n",
      "\n",
      "     Attributes:\n",
      "        classes (list): List of the class names sorted alphabetically.\n",
      "        class_to_idx (dict): Dict with items (class_name, class_index).\n",
      "        samples (list): List of (sample path, class_index) tuples\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(\n",
      "            self,\n",
      "            dataframe: pd.DataFrame,\n",
      "            label_id: str,\n",
      "            label_target: str,\n",
      "            root: typing.Optional[typing.Union[str, os.PathLike]] = None,\n",
      "            extension: typing.Optional[str] = None,\n",
      "            class_to_idx: typing.Optional[typing.Dict[typing.Any, int]] = None,\n",
      "            transform: typing.Optional[typing.Callable] = None,\n",
      "            target_transform: typing.Optional[typing.Callable] = None,\n",
      "            extras_transform: typing.Optional[typing.Callable] = None,\n",
      "            loader: typing.Callable[[str], typing.Any] = default_loader,\n",
      "    ) -> None:\n",
      "\n",
      "        super(ImageWithPandas, self).__init__(root, None, transform, target_transform)\n",
      "\n",
      "        self.extras_transform = extras_transform\n",
      "        self.loader = loader\n",
      "        self.label_id = label_id\n",
      "        self.label_target = label_target\n",
      "\n",
      "        labels = [label_id, label_target]\n",
      "\n",
      "        samples = dataframe[labels].copy(deep=True)\n",
      "\n",
      "        assert extension.startswith('.') or extension is None\n",
      "        if root is not None:\n",
      "            root = os.path.expanduser(root)\n",
      "        if root is not None or extension is not None:\n",
      "            samples[label_id] = samples[label_id].map(\n",
      "                (lambda x: os.path.join(root, x + extension or ''))\n",
      "                if root is not None else (lambda x: x + extension)\n",
      "            )\n",
      "\n",
      "        classes = sorted(samples[label_target].unique())\n",
      "        if class_to_idx is None:\n",
      "            class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
      "        samples[label_target] = samples[label_target].map(lambda x: class_to_idx[x])\n",
      "\n",
      "        samples = samples.drop_duplicates()\n",
      "        samples.index = range(len(samples))\n",
      "\n",
      "        self.samples = samples\n",
      "        self.classes = classes\n",
      "        self.class_to_idx = class_to_idx\n",
      "        self.num_classes = len(class_to_idx)\n",
      "\n",
      "    def get_labels(self):\n",
      "        return list(self.samples[self.label_target])\n",
      "\n",
      "    def __len__(self):\n",
      "        return len(self.samples)\n",
      "\n",
      "    def __getitem__(self, index: int) -> ...:\n",
      "        row = self.samples.iloc[index]\n",
      "        path, target = row[self.label_id], row[self.label_target]\n",
      "        sample = self.loader(path)\n",
      "        if self.transform is not None:\n",
      "            sample = self.transform(sample)\n",
      "        if self.target_transform is not None:\n",
      "            target = self.target_transform(target)\n",
      "        else:\n",
      "            target = np.array(target)\n",
      "        return sample, target\n",
      "\n",
      "class ImageFolder(_ImageFolder):\n",
      "    \"\"\"A generic data loader where the images are arranged in root folder.\n",
      "\n",
      "    Args:\n",
      "        root (string): Root directory path.\n",
      "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
      "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      "        target_transform (callable, optional): A function/transform that takes in the\n",
      "            target and transforms it.\n",
      "        loader (callable, optional): A function to load an image given its path.\n",
      "        is_valid_file (callable, optional): A function that takes path of an Image file\n",
      "            and check if the file is a valid file (used to check of corrupt files)\n",
      "\n",
      "     Attributes:\n",
      "        classes (list): List of the class names sorted alphabetically.\n",
      "        class_to_idx (dict): Dict with items (class_name, class_index).\n",
      "        imgs (list): List of (image path, class_index) tuples\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(\n",
      "            self,\n",
      "            root: typing.Union[str, os.PathLike],\n",
      "            class_to_idx: typing.Optional[typing.Dict[str, int]] = None,\n",
      "            transform: typing.Optional[typing.Callable] = None,\n",
      "            target_transform: typing.Optional[typing.Callable] = None,\n",
      "            loader: typing.Callable[[str], typing.Any] = default_loader,\n",
      "            is_valid_file: typing.Optional[typing.Callable[[str], bool]] = None,\n",
      "    ):\n",
      "        self.class_to_idx = class_to_idx\n",
      "        super(ImageFolder, self).__init__(root, transform, target_transform, loader, is_valid_file)\n",
      "\n",
      "    def _find_classes(self, directory: str) -> typing.Tuple[typing.List[str], typing.Dict[str, int]]:\n",
      "        \"\"\"\n",
      "        Finds the class folders in a dataset.\n",
      "\n",
      "        Args:\n",
      "            directory (string): Root directory path.\n",
      "\n",
      "        Returns:\n",
      "            tuple: (classes, class_to_idx) where classes are relative to (dir), and class_to_idx is a dictionary.\n",
      "\n",
      "        Ensures:\n",
      "            No class is a subdirectory of another.\n",
      "        \"\"\"\n",
      "        classes = [d.name for d in os.scandir(directory) if d.is_dir()]\n",
      "        classes.sort()\n",
      "        try:\n",
      "            class_to_idx = self.class_to_idx\n",
      "        except AttributeError:\n",
      "            class_to_idx = None\n",
      "        if class_to_idx is None:\n",
      "            class_to_idx = self.class_to_idx or {cls_name: i for i, cls_name in enumerate(classes)}\n",
      "        return classes, class_to_idx\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dataset Class Source Code\n",
    "\n",
    "print(inspect.getsource(data_prep_utils.dataset.ImageWithPandas))\n",
    "print(inspect.getsource(data_prep_utils.dataset.ImageFolder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Resize(256),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    # torchvision.transforms.Normalize(mean=[0.45],std=[0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_train_transforms():\n",
    "    return A.Compose(\n",
    "        [\n",
    "            # A.RandomSizedCrop(min_max_height=(1024, 1024), height=1024, width=1024, p=0.5),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.2,\n",
    "                                       contrast_limit=0.2, p=0.9),\n",
    "            # A.ToGray(p=0.01),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            # A.VerticalFlip(p=0.5),\n",
    "            A.Resize(height=256, width=256, p=1),\n",
    "            # A.Cutout(num_holes=8, max_h_size=64, max_w_size=64, fill_value=0, p=0.5),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ],\n",
    "        p=1.0,\n",
    "        bbox_params=A.BboxParams(\n",
    "            format='pascal_voc',\n",
    "            min_area=0,\n",
    "            min_visibility=0,\n",
    "            label_fields=['labels']\n",
    "        )\n",
    "    )\n",
    "\n",
    "def get_valid_transforms():\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.Resize(height=256, width=256, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ],\n",
    "        p=1.0,\n",
    "        bbox_params=A.BboxParams(\n",
    "            format='pascal_voc',\n",
    "            min_area=0,\n",
    "            min_visibility=0,\n",
    "            label_fields=['labels']\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "classification_dataset_1 = rsna_pneumonia_detection_challenge.torch_classification_dataset(data_transform)\n",
    "\n",
    "classification_dataset_2 = covid_19_radiography_dataset.torch_classification_dataset(data_transform)\n",
    "\n",
    "detection_dataset = rsna_pneumonia_detection_challenge.torch_detection_dataset(get_train_transforms())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Make data loader from dataset\n",
    "\n",
    "from data_prep_utils.samplers import ImbalancedDatasetSampler\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "train_loader_cls_1 = torch.utils.data.DataLoader(classification_dataset_1,\n",
    "                                                 sampler=ImbalancedDatasetSampler(classification_dataset_1),\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 # shuffle=True,\n",
    "                                                 num_workers=2)\n",
    "train_loader_cls_2 = torch.utils.data.DataLoader(classification_dataset_2,\n",
    "                                                 sampler=ImbalancedDatasetSampler(classification_dataset_2),\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 # shuffle=True,\n",
    "                                                 num_workers=2)\n",
    "\n",
    "train_loader_det_1 = torch.utils.data.DataLoader(\n",
    "        detection_dataset,\n",
    "        batch_size=2,\n",
    "        shuffle=True,\n",
    "        # pin_memory=False,\n",
    "        num_workers=2\n",
    ")\n",
    "\n",
    "train_loader_det_1_prime = rsna_pneumonia_detection_challenge.torch_detection_dataset(\n",
    "    get_train_transforms(),\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    # pin_memory=False,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "train_loaders = [\n",
    "    train_loader_cls_1,\n",
    "    # train_loader_cls_2,\n",
    "    train_loader_det_1_prime\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design Model Architecture\n",
    "* Base Model: EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from models.efficientnet import get_efficientnet_backbone\n",
    "\n",
    "efficientnet_backbone = get_efficientnet_backbone(\n",
    "    depth=4, in_channels=1, image_size=None,\n",
    "    pretrained=colaboratory,  # FIXME: set this as true\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "\n",
    "    def __init__(self, backbone, num_classes, out_channels=None, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        out_channels = out_channels or backbone.out_channels\n",
    "        self.feature_extractor = backbone\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(out_channels, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def get_classifier(backbone, num_classes):\n",
    "    return Classifier(backbone, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.anchor_utils import AnchorGenerator\n",
    "from torchvision.models.detection.transform import GeneralizedRCNNTransform\n",
    "\n",
    "\n",
    "def get_detector(backbone, num_classes=2, max_size=800, min_size=1333, **kwargs):\n",
    "\n",
    "    anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256),),\n",
    "                                       aspect_ratios=((0.5, 1.0, 2.0),))\n",
    "    detector = FasterRCNN(backbone, num_classes, rpn_anchor_generator=anchor_generator, **kwargs)\n",
    "    detector.transform = GeneralizedRCNNTransform(min_size, max_size, image_mean=[0.485], image_std=[0.229])\n",
    "    return detector\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "model_c = get_classifier(efficientnet_backbone, 4)\n",
    "model_d = get_detector(efficientnet_backbone)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "num_epochs = 3\n",
    "\n",
    "opt_c = torch.optim.AdamW(model_c.parameters(), lr=0.00005)\n",
    "opt_d = torch.optim.AdamW(model_d.parameters(), lr=0.0001)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "dset = ConcatDataset([\n",
    "    classification_dataset_1,\n",
    "    classification_dataset_2\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advanced Fitter Initialized.\n",
      "\n",
      "<Start Learning> \t\t\t\tTotal 1 epochs\n",
      "\n",
      "Epoch 1\n",
      "12\n",
      "52\n",
      "11\n",
      "68\n",
      "81\n",
      "[Train]\t Progress: 1/100 (01.00%), \tLoss: 1.285691 88\n",
      "[Train]\t Progress: 2/100 (02.00%), \tLoss: 1.531008 54\n",
      "[Train]\t Progress: 3/100 (03.00%), \tLoss: 1.437010 24\n",
      "[Train]\t Progress: 4/100 (04.00%), \tLoss: 1.264676 40\n",
      "[Train]\t Progress: 5/100 (05.00%), \tLoss: 1.300494 5\n",
      "[Train]\t Progress: 6/100 (06.00%), \tLoss: 1.169945 84\n",
      "[Train]\t Progress: 7/100 (07.00%), \tLoss: 1.139261 26\n",
      "[Train]\t Progress: 8/100 (08.00%), \tLoss: 1.089011 23\n",
      "[Train]\t Progress: 9/100 (09.00%), \tLoss: 1.114672 44\n",
      "[Train]\t Progress: 10/100 (10.00%), \tLoss: 1.100678 34\n",
      "[Train]\t Progress: 11/100 (11.00%), \tLoss: 1.144141 49\n",
      "[Train]\t Progress: 12/100 (12.00%), \tLoss: 0.911792 70\n",
      "[Train]\t Progress: 13/100 (13.00%), \tLoss: 0.764387 24\n",
      "[Train]\t Progress: 14/100 (14.00%), \tLoss: 1.295549 33\n",
      "[Train]\t Progress: 15/100 (15.00%), \tLoss: 0.832546 67\n",
      "[Train]\t Progress: 16/100 (16.00%), \tLoss: 1.193624 46\n",
      "[Train]\t Progress: 17/100 (17.00%), \tLoss: 1.194484 54\n",
      "[Train]\t Progress: 18/100 (18.00%), \tLoss: 0.684495 43\n",
      "[Train]\t Progress: 19/100 (19.00%), \tLoss: 1.100923 74\n",
      "[Train]\t Progress: 20/100 (20.00%), \tLoss: 1.205341 7\n",
      "[Train]\t Progress: 21/100 (21.00%), \tLoss: 1.164683 93\n",
      "[Train]\t Progress: 22/100 (22.00%), \tLoss: 0.586718 93\n",
      "[Train]\t Progress: 23/100 (23.00%), \tLoss: 0.619990 35\n",
      "[Train]\t Progress: 24/100 (24.00%), \tLoss: 0.650069 76\n",
      "[Train]\t Progress: 25/100 (25.00%), \tLoss: 1.146049 76\n",
      "[Train]\t Progress: 26/100 (26.00%), \tLoss: 0.687414 84\n",
      "[Train]\t Progress: 27/100 (27.00%), \tLoss: 0.607690 20\n",
      "[Train]\t Progress: 28/100 (28.00%), \tLoss: 0.980988 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x11ff71160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/python-dl/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1324, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/python-dl/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1297, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/python-dl/lib/python3.8/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/python-dl/lib/python3.8/multiprocessing/popen_fork.py\", line 44, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/python-dl/lib/python3.8/multiprocessing/connection.py\", line 931, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/python-dl/lib/python3.8/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<Stop Learning> \tLeast loss: inf\tDuration: 23.65s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/0n/z3tlqlk136v990dbw2gx0rkc0000gn/T/ipykernel_8168/620487251.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[0mfitter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'cuda'\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_available\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;34m'cpu'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[0;32mwith\u001B[0m \u001B[0mfitter\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 16\u001B[0;31m     \u001B[0mfitter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     17\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Projects/Python/Chest-X-Ray-Detection/train_utils/trainer_base.py\u001B[0m in \u001B[0;36mrun\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    417\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    418\u001B[0m                 \u001B[0;32mwhile\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_current_epoch\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtotal_epoch\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 419\u001B[0;31m                     \u001B[0mresult\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    420\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    421\u001B[0m             \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Projects/Python/Chest-X-Ray-Detection/train_utils/trainer_base.py\u001B[0m in \u001B[0;36mstep\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    384\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_log_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_current_epoch\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    385\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 386\u001B[0;31m         \u001B[0mtrain_args\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_train\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    387\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_save\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    388\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Projects/Python/Chest-X-Ray-Detection/train_utils/trainer_advanced.py\u001B[0m in \u001B[0;36m_train\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     95\u001B[0m                 \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     96\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 97\u001B[0;31m                     \u001B[0ml\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_train_classification\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     98\u001B[0m                     \u001B[0mtotal_loss\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0ml\u001B[0m\u001B[0;34m;\u001B[0m \u001B[0mtotal_batch\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     99\u001B[0m                     \u001B[0;32mif\u001B[0m \u001B[0miteration\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0mlog_interval\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m0\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mverbose\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Projects/Python/Chest-X-Ray-Detection/train_utils/trainer_advanced.py\u001B[0m in \u001B[0;36m_train_classification\u001B[0;34m(self, dataset)\u001B[0m\n\u001B[1;32m    115\u001B[0m         \u001B[0mimage\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mimage\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    116\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 117\u001B[0;31m         \u001B[0mlogit\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodel_c\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimage\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    118\u001B[0m         \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfunctional\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcross_entropy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlogit\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    119\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/python-dl/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    887\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    888\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 889\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    890\u001B[0m         for hook in itertools.chain(\n\u001B[1;32m    891\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/0n/z3tlqlk136v990dbw2gx0rkc0000gn/T/ipykernel_8168/2557469987.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 12\u001B[0;31m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfeature_extractor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     13\u001B[0m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdropout\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mflatten\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/python-dl/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    887\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    888\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 889\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    890\u001B[0m         for hook in itertools.chain(\n\u001B[1;32m    891\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/python-dl/lib/python3.8/site-packages/efficientnet_pytorch/model.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m    312\u001B[0m         \"\"\"\n\u001B[1;32m    313\u001B[0m         \u001B[0;31m# Convolution layers\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 314\u001B[0;31m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mextract_features\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    315\u001B[0m         \u001B[0;31m# Pooling and final linear layer\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    316\u001B[0m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_avg_pooling\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/python-dl/lib/python3.8/site-packages/efficientnet_pytorch/model.py\u001B[0m in \u001B[0;36mextract_features\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m    294\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mdrop_connect_rate\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    295\u001B[0m                 \u001B[0mdrop_connect_rate\u001B[0m \u001B[0;34m*=\u001B[0m \u001B[0mfloat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m/\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_blocks\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# scale drop connect_rate\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 296\u001B[0;31m             \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mblock\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdrop_connect_rate\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdrop_connect_rate\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    297\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    298\u001B[0m         \u001B[0;31m# Head\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/python-dl/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    887\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    888\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 889\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    890\u001B[0m         for hook in itertools.chain(\n\u001B[1;32m    891\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/python-dl/lib/python3.8/site-packages/efficientnet_pytorch/model.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, inputs, drop_connect_rate)\u001B[0m\n\u001B[1;32m    107\u001B[0m             \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_swish\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    108\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 109\u001B[0;31m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_depthwise_conv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    110\u001B[0m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_bn1\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    111\u001B[0m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_swish\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/python-dl/lib/python3.8/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    887\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    888\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 889\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    890\u001B[0m         for hook in itertools.chain(\n\u001B[1;32m    891\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/python-dl/lib/python3.8/site-packages/efficientnet_pytorch/utils.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    273\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    274\u001B[0m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstatic_padding\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 275\u001B[0;31m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconv2d\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstride\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpadding\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdilation\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgroups\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    276\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    277\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from train_utils import AdvancedFitter\n",
    "\n",
    "fitter = AdvancedFitter(\n",
    "    model_c, model_d,\n",
    "    opt_c, opt_d,\n",
    "    num_epochs,\n",
    "    train_iter = train_loaders,\n",
    "    val_iter = train_loaders,\n",
    "    snapshot_dir = 'snapshots',\n",
    "    verbose=True,\n",
    "    timer=True,\n",
    "    log_interval=1,\n",
    ")\n",
    "fitter.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "with fitter:\n",
    "    fitter.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_next():\n",
    "    try:\n",
    "        iterator = iter(train_loaders[0])\n",
    "        return next(iterator)\n",
    "    except RuntimeError:  # 오류안뜰때까지 뽑아보자\n",
    "        return get_next()\n",
    "\n",
    "    \n",
    "nxt = get_next()\n",
    "print({k: v.shape for k, v in nxt.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(train_loaders[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}